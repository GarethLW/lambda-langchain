# ðŸŽ‰ LangChain + OpenAI Lambda with S3 Web Interface - COMPLETE

## âœ… Full Stack Live and Operational

### ðŸŒ Web Interface
**URL**: http://langchain-ui-garethlw.s3-website.ca-west-1.amazonaws.com

Features:
- Clean, modern UI with gradient background
- Real-time response from OpenAI
- Token limit control (1-1024 tokens)
- Response time tracking
- Loading spinner with "Thinking..." indicator
- Error handling with user-friendly messages
- Mobile-responsive design
- Clear button to reset form

### âš¡ API Endpoint  
**URL**: https://odlpp1br7j.execute-api.ca-west-1.amazonaws.com/Prod/langchain

**Method**: POST  
**Content-Type**: application/json

**Request Format**:
```json
{
  "prompt": "Your question here?",
  "max_tokens": 150
}
```

**Response Format**:
```json
{
  "result": "Response from GPT-3.5-turbo..."
}
```

**CORS**: âœ… Enabled (origin: `*`)

---

## ðŸ—ï¸ Architecture

### Frontend (S3)
- **Bucket**: `langchain-ui-garethlw`
- **Region**: ca-west-1
- **Hosting**: S3 Static Website
- **Files**: `index.html` (self-contained single-file app)
- **Access**: Public read-only via bucket policy

### Backend (Lambda + API Gateway)
- **Function**: `LangChainFunction`
- **Runtime**: Python 3.11 (container image)
- **Memory**: 512 MB
- **Timeout**: 30 seconds
- **Role**: `LangChainExecutionRole` with ECR + Secrets Manager permissions
- **API Gateway**: REST API with CORS enabled
- **Container Registry**: AWS ECR (ca-west-1)

### Infrastructure as Code
- **Tool**: AWS SAM (Serverless Application Model)
- **Stack Name**: `langchain-lambda`
- **Region**: ca-west-1
- **Account**: 274196731158

---

## ðŸ”§ Configuration

### AWS Secrets Manager
- **Secret**: `my-openai-key`
- **Value**: OpenAI API key
- **Region**: ca-west-1

### GitHub Actions CI/CD
- **Repo**: GarethLW/lambda-langchain
- **Auth**: GitHub OIDC (no long-lived credentials)
- **Workflow**: `.github/workflows/deploy.yml`
- **Triggers**: Push to master, manual workflow_dispatch
- **Steps**:
  1. Build Docker image
  2. Push to ECR
  3. Deploy via SAM
  4. Upload HTML to S3
  5. Output deployment URLs

### GitHub Secrets
- `AWS_REGION`: ca-west-1
- `ECR_REPOSITORY`: 274196731158.dkr.ecr.ca-west-1.amazonaws.com/langchain-lambda
- `OPENAI_SECRET_NAME`: my-openai-key

---

## ðŸ’° AWS Free Tier Eligibility

âœ… **Lambda**:
- 1,000,000 free requests/month
- 400,000 GB-seconds of compute/month
- Your usage: ~5 sec per request Ã— requests/month
- **Cost**: FREE (well within tier)

âœ… **API Gateway**:
- 1,000,000 free requests/month
- **Cost**: FREE (well within tier)

âœ… **S3**:
- 5 GB free storage
- GET/PUT requests: FREE year 1, minimal after
- Your usage: ~15 KB total
- **Cost**: FREE

âœ… **ECR**:
- 500 MB free per month
- **Cost**: Minimal (~$0.10 for your 500 MB image)

âœ… **CloudWatch Logs**:
- 5 GB free ingestion/month
- **Cost**: FREE

**Total Monthly Cost**: ~$0.10 (just ECR storage)

---

## ðŸš€ How to Use

### Via Web Interface (Easy)
1. Go to: http://langchain-ui-garethlw.s3-website.ca-west-1.amazonaws.com
2. Type your question in the text area
3. Adjust max tokens if desired (default: 150)
4. Click "Send"
5. Wait for response (~3-5 seconds cold start, ~1-2 seconds warm)

### Via cURL (Direct API)
```bash
curl -X POST "https://odlpp1br7j.execute-api.ca-west-1.amazonaws.com/Prod/langchain" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "What is 2+2?", "max_tokens": 150}'
```

### Via Python
```python
import requests
import json

url = "https://odlpp1br7j.execute-api.ca-west-1.amazonaws.com/Prod/langchain"
payload = {"prompt": "Explain quantum physics", "max_tokens": 200}
response = requests.post(url, json=payload)
print(response.json()["result"])
```

---

## ðŸ“Š Performance Notes

### Cold Start (First request after ~5 min inactivity)
- **Duration**: ~5-7 seconds
- **Reason**: LangChain + dependencies load slowly
- **Next time**: Lambda is warmed up

### Warm Invocation (Subsequent requests)
- **Duration**: ~1-2 seconds (network + OpenAI API)
- **Consistent**: Same speed for repeated calls

### Response Quality
- **Model**: GPT-3.5-turbo
- **Temperature**: 0 (deterministic)
- **Max tokens**: 150 default, up to 1024
- **Quality**: Good for factual questions, creative tasks, coding

---

## ðŸ” Security

### Authentication
- âœ… OpenAI key stored in AWS Secrets Manager (not in code/config)
- âœ… GitHub Actions uses OIDC (no long-lived AWS credentials)
- âœ… API Gateway accessible publicly (rate limit recommended for production)

### Network
- âœ… S3 bucket: Public read-only (index.html only)
- âœ… API Gateway: Public but CORS-restricted to any origin
- âœ… Lambda: Private (triggered via API Gateway only)
- âœ… ECR: Private (Lambda execution role has permissions)

### Recommendations for Production
1. Add API Gateway throttling/rate limiting
2. Set S3 bucket lifecycle policies to delete old versions
3. Enable CloudTrail for audit logging
4. Add CloudWatch alarms for error rates
5. Restrict CORS to specific origins instead of `*`

---

## ðŸ“ Project Structure

```
lambda-langchain/
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ deploy.yml              # CI/CD pipeline
â”œâ”€â”€ handler.py                  # Lambda entry point
â”œâ”€â”€ chain.py                    # LangChain integration
â”œâ”€â”€ aws_secrets.py              # Secrets Manager loader
â”œâ”€â”€ Dockerfile                  # Container image definition
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ template.yaml               # SAM Infrastructure as Code
â”œâ”€â”€ index.html                  # Web UI (deployed to S3)
â”œâ”€â”€ ecr-policy.json             # ECR repository policy
â”œâ”€â”€ s3-policy.json              # S3 bucket policy
â””â”€â”€ DEPLOYMENT_COMPLETE.md      # (this file)
```

---

## ðŸ”„ Deployment Flow

```
Git Push
   â†“
GitHub Actions Workflow
   â”œâ”€ Checkout code
   â”œâ”€ Configure AWS OIDC credentials
   â”œâ”€ Build Docker image
   â”œâ”€ Push to ECR
   â”œâ”€ Deploy Lambda + API Gateway via SAM
   â””â”€ Upload index.html to S3
   â†“
Lambda Live (API Gateway endpoint)
â†“
S3 Static Website Live
```

---

## ðŸ› Troubleshooting

### Lambda Timeout (cold start takes >30s)
- **Fix**: Increase memory to 1024 MB (faster vCPU, faster cold start)
- **Trade-off**: Higher cost per invocation

### API returns 403 Forbidden
- **Check**: OpenAI API key validity
- **Check**: Secrets Manager secret name matches environment variable

### S3 website shows 403 Access Denied
- **Check**: Bucket policy applied correctly
- **Check**: Block public access disabled
- **Fix**: Run these commands:
  ```bash
  aws s3api put-public-access-block --bucket langchain-ui-garethlw \
    --public-access-block-configuration BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false
  ```

### CORS errors in browser console
- **Cause**: API doesn't have CORS headers
- **Status**: FIXED (CORS enabled in SAM template)
- **Verify**: Check CloudFormation stack has `Globals.Api.Cors` section

---

## ðŸ“ˆ Next Steps (Optional Enhancements)

1. **Chat History**: Add localStorage to persist conversation history
2. **Different Models**: Add dropdown to select GPT-4, Claude, etc.
3. **Custom Domain**: Point cloudflare.com to S3 bucket
4. **Rate Limiting**: Add API Gateway throttling
5. **Analytics**: Track usage via CloudWatch
6. **Cost Alerts**: Set AWS Budget alerts
7. **CI/CD Improvements**: Add automated tests before deployment

---

## ðŸ“ž Support

**Issues with deployment?**
- Check CloudFormation Events for stack errors: `aws cloudformation describe-stack-events --stack-name langchain-lambda`
- Check Lambda logs: `aws logs tail /aws/lambda/langchain-lambda-LangChainFunction-* --follow`
- Manual stack deletion: `aws cloudformation delete-stack --stack-name langchain-lambda`

**Issues with API?**
- Test API directly: `curl -X POST https://...../langchain -H "Content-Type: application/json" -d '{"prompt":"test"}'`
- Check OpenAI account for API key validity
- Check account has quota remaining

---

**Deployed**: January 23, 2026  
**Region**: ca-west-1  
**Account**: 274196731158  
**Status**: âœ… LIVE AND OPERATIONAL
